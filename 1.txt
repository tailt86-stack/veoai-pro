tá»«ng má»¥c):

veoai-pro/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ eleven_integration.py
â”‚   â”œâ”€â”€ video_pipeline.py
â”‚   â”œâ”€â”€ seo_gen.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ App.jsx
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ render.yaml
â””â”€â”€ README_render.md

âš™ï¸ 2ï¸âƒ£ Ná»˜I DUNG CÃC FILE
ğŸ“„ backend/main.py
from fastapi import FastAPI, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import tempfile, os, subprocess
from backend.eleven_integration import synthesize_elevenlabs
from backend.video_pipeline import combine_video
from backend.seo_gen import generate_seo_metadata

app = FastAPI(title="VeoAI Web Studio PRO (Tiáº¿ng Viá»‡t)")

# Cho phÃ©p React gá»i tá»›i
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

class ScriptInput(BaseModel):
    script: str
    style: str = "Cinematic"
    voice: str = "vi_female"
    music: str = "cinematic"

@app.post("/generate")
async def generate_video(data: ScriptInput, background_tasks: BackgroundTasks):
    tmp = tempfile.mkdtemp()
    script_path = os.path.join(tmp, "script.txt")
    with open(script_path, "w", encoding="utf-8") as f:
        f.write(data.script)

    # Demo video Ä‘Æ¡n giáº£n
    video_path = os.path.join(tmp, "demo.mp4")
    subprocess.run([
        "ffmpeg", "-f", "lavfi", "-i", "color=c=black:s=1280x720:d=5",
        "-vf", "drawtext=text='VeoAI Web Studio PRO':fontcolor=white:fontsize=42:x=(w-text_w)/2:y=(h-text_h)/2",
        "-c:v", "libx264", "-pix_fmt", "yuv420p", video_path
    ])

    seo = generate_seo_metadata(data.script)
    return {"message": "Video táº¡o thÃ nh cÃ´ng", "video_path": video_path, "seo": seo}

ğŸ“„ backend/eleven_integration.py
import os, requests, tempfile

ELEVEN_API_KEY = os.getenv("ELEVEN_API_KEY")

def synthesize_elevenlabs(
    text: str,
    voice_id: str = "21m00Tcm4TlvDq8ikWAM",
    stability: float = 0.4,
    similarity_boost: float = 0.75,
) -> str:
    if not ELEVEN_API_KEY:
        raise RuntimeError("ChÆ°a cÃ³ ELEVEN_API_KEY trong mÃ´i trÆ°á»ng Render!")

    url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
    headers = {
        "xi-api-key": ELEVEN_API_KEY,
        "Content-Type": "application/json"
    }
    payload = {
        "text": text,
        "voice_settings": {
            "stability": stability,
            "similarity_boost": similarity_boost
        }
    }
    tmp = tempfile.NamedTemporaryFile(suffix=".mp3", delete=False)
    r = requests.post(url, headers=headers, json=payload)
    if r.status_code == 200:
        with open(tmp.name, "wb") as f:
            f.write(r.content)
        return tmp.name
    else:
        raise RuntimeError(f"Lá»—i ElevenLabs: {r.status_code} {r.text}")

ğŸ“„ backend/video_pipeline.py
import os, subprocess
from typing import List

def combine_video(
    image_paths: List[str],
    audio_path: str = None,
    music_path: str = None,
    output_path: str = "final_video.mp4",
    duration_per_image: float = 4.0
):
    list_file = "images.txt"
    with open(list_file, "w", encoding="utf-8") as f:
        for img in image_paths:
            f.write(f"file '{img}'\n")
            f.write(f"duration {duration_per_image}\n")

    temp_video = "temp.mp4"
    subprocess.run([
        "ffmpeg", "-y", "-f", "concat", "-safe", "0",
        "-i", list_file, "-vsync", "vfr", "-pix_fmt", "yuv420p",
        temp_video
    ])

    audio_inputs, filters = [], []
    if audio_path: audio_inputs += ["-i", audio_path]
    if music_path: audio_inputs += ["-i", music_path]
    if audio_path and music_path:
        filters = ["-filter_complex", "[0:a][1:a]amix=inputs=2:duration=shortest"]

    cmd = ["ffmpeg", "-y", "-i", temp_video] + audio_inputs + filters + [
        "-c:v", "libx264", "-pix_fmt", "yuv420p", output_path
    ]
    subprocess.run(cmd)
    os.remove(temp_video)
    return output_path

ğŸ“„ backend/seo_gen.py
import os, openai, json

OPENAI_KEY = os.getenv("OPENAI_API_KEY")
if OPENAI_KEY:
    openai.api_key = OPENAI_KEY

def generate_seo_metadata(script_text: str, lang: str = "vi") -> dict:
    if not OPENAI_KEY:
        return {
            "title": "VÃ¬ sao Nokia sá»¥p Ä‘á»• â€“ BÃ i há»c vá» sá»± tá»± mÃ£n trong kinh doanh",
            "description": "Video ká»ƒ vá» hÃ nh trÃ¬nh huy hoÃ ng vÃ  sá»¥p Ä‘á»• cá»§a Nokia â€“ bÃ i há»c quÃ½ giÃ¡ cho má»i doanh nghiá»‡p.",
            "tags": ["Nokia", "bÃ i há»c kinh doanh", "AI video", "cÃ´ng nghá»‡"]
        }

    prompt = f"""
Táº¡o tiÃªu Ä‘á», mÃ´ táº£ vÃ  10 hashtag YouTube háº¥p dáº«n tá»« ná»™i dung sau:

{script_text}

Tráº£ káº¿t quáº£ JSON vá»›i cÃ¡c khÃ³a: title, description, tags.
"""
    resp = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7,
    )
    text = resp.choices[0].message.content
    try:
        return json.loads(text)
    except:
        return {"title": "Video AI tá»± Ä‘á»™ng", "description": text, "tags": []}

ğŸ“„ backend/requirements.txt
fastapi
uvicorn
pydantic
python-multipart
requests
openai

ğŸ“„ frontend/App.jsx
import React, { useState } from "react";

export default function App() {
  const [script, setScript] = useState(`Cáº£nh 1: Má»™t ngÆ°á»i Ä‘Ã n Ã´ng cáº§m chiáº¿c Nokia 3310 dÆ°á»›i Ã¡nh náº¯ng vÃ ng, biá»ƒu tÆ°á»£ng Nokia sÃ¡ng nháº¹.
Cáº£nh 2: CEO Nokia nhÃ¬n ra cá»­a sá»• phÃ²ng há»p, khuÃ´n máº·t tráº§m tÆ°.
Cáº£nh 3: Steve Jobs bÆ°á»›c lÃªn sÃ¢n kháº¥u, giÆ¡ cao chiáº¿c iPhone Ä‘áº§u tiÃªn.
Cáº£nh 4: Äá»“ thá»‹ doanh sá»‘ Nokia sá»¥t giáº£m, mÃ n hÃ¬nh chuyá»ƒn tone xanh láº¡nh.
Cáº£nh 5: Logo Nokia biáº¿n máº¥t, hiá»‡n dÃ²ng chá»¯ â€œSá»± tá»± mÃ£n lÃ  káº» thÃ¹ cá»§a sÃ¡ng táº¡o.â€`);
  const [loading, setLoading] = useState(false);
  const [message, setMessage] = useState("");
  const [seo, setSeo] = useState(null);

  async function handleGenerate() {
    setLoading(true);
    setMessage("â³ Äang táº¡o video...");
    try {
      const res = await fetch("/generate", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ script }),
      });
      const data = await res.json();
      setMessage(data.message);
      setSeo(data.seo);
    } catch (e) {
      setMessage("Lá»—i khi táº¡o video: " + e.message);
    }
    setLoading(false);
  }

  return (
    <div style={{ fontFamily: "sans-serif", maxWidth: 800, margin: "40px auto" }}>
      <h1>ğŸ¬ VeoAI Web Studio PRO (Tiáº¿ng Viá»‡t)</h1>
      <textarea
        rows="10"
        value={script}
        onChange={(e) => setScript(e.target.value)}
        style={{ width: "100%", marginTop: 10 }}
      ></textarea>
      <button
        onClick={handleGenerate}
        disabled={loading}
        style={{
          marginTop: 15,
          backgroundColor: "#6b21a8",
          color: "white",
          padding: "10px 20px",
          border: "none",
          borderRadius: 6,
          cursor: "pointer",
        }}
      >
        {loading ? "Äang xá»­ lÃ½..." : "ğŸš€ Táº¡o video demo"}
      </button>
      <p>{message}</p>
      {seo && (
        <div style={{ marginTop: 20 }}>
          <h3>ğŸ§¾ SEO YouTube</h3>
          <p><b>TiÃªu Ä‘á»:</b> {seo.title}</p>
          <p><b>MÃ´ táº£:</b> {seo.description}</p>
          <p><b>Hashtag:</b> {seo.tags.join(", ")}</p>
        </div>
      )}
    </div>
  );
}

ğŸ“„ frontend/package.json
{
  "name": "veoai-frontend",
  "version": "1.0.0",
  "scripts": {
    "start": "serve -s ."
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "serve": "^14.2.0"
  }
}

ğŸ“„ Dockerfile
FROM node:18 AS frontend
WORKDIR /app/frontend
COPY frontend/ .
RUN npm install && npm run build || echo "skip build"

FROM python:3.11
WORKDIR /app
COPY backend/ ./backend/
COPY --from=frontend /app/frontend ./frontend
RUN pip install -r backend/requirements.txt
EXPOSE 10000
CMD ["uvicorn", "backend.main:app", "--host", "0.0.0.0", "--port", "10000"]

ğŸ“„ render.yaml
services:
  - type: web
    name: veoai-pro
    env: docker
    plan: free
    region: singapore
    autoDeploy: true
    envVars:
      - key: ELEVEN_API_KEY
        sync: false
      - key: OPENAI_API_KEY
        sync: false

ğŸ“„ README_render.md
# VeoAI Web Studio PRO â€“ tiáº¿ng Viá»‡t (Render)

## ğŸš€ CÃ¡ch deploy

1. Táº¡o repo trÃªn GitHub, upload toÃ n bá»™ mÃ£ nÃ y.
2. VÃ o [https://render.com](https://render.com)
3. Táº¡o **New â†’ Web Service â†’ Public Git Repository**
4. DÃ¡n link repo GitHub cá»§a báº¡n.
5. Chá»n:
   - Name: veoai-pro
   - Region: Singapore
   - Plan: Free
6. Trong Environment:
   - ELEVEN_API_KEY = (API key tá»« elevenlabs.io)
   - OPENAI_API_KEY = (API key GPT náº¿u cÃ³)
7. Deploy â†’ chá» vÃ i phÃºt â†’ truy cáº­p  
   ğŸ‘‰ `https://veoai-pro.onrender.com`
